{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNWoa5Bj3S1hbQeiGfgRwRo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamesstaub/Listen-Up/blob/main/audio_slicer_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "nxOJbneh3RMw"
      },
      "outputs": [],
      "source": [
        "# @title 1. Install Dependencies & Import Libraries\n",
        "!pip install -q umap-learn\n",
        "!pip install -q librosa soundfile ipywidgets\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
        "import umap\n",
        "from scipy.spatial.distance import cdist\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# @title 2. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Drive Mounted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzuVvHi_3coj",
        "outputId": "666586ce-8040-4ee4-918b-6081da5a77cd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Drive Mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\n",
        "    # ---- paths ----\n",
        "    \"input_folder\": \"/content/drive/My Drive/audio/sp-tools-corpora/preparedpiano\",\n",
        "    \"output_folder\": \"/content/drive/My Drive/audio/sp-tools-corpora/preparedpiano/clusters\",\n",
        "    \"data_file\": \"/content/drive/My Drive/audio/sp-tools-corpora/preparedpiano/clusters/analysis_data.csv\",\n",
        "\n",
        "    # ---- behavior ----\n",
        "    \"resume\": False,        # load existing analysis if present\n",
        "    \"clear_existing\": True,  # nuke data + clusters before run\n",
        "\n",
        "    # ---- audio ----\n",
        "    \"sample_rate\": 22050,\n",
        "    \"stereo_mode\": \"sum\",\n",
        "    \"file_limit\": 3,\n",
        "\n",
        "    \"min_duration\": 0.1,\n",
        "    \"max_duration\": 8.0,\n",
        "\n",
        "    # ---- clustering ----\n",
        "    \"n_clusters\": 8,\n",
        "\n",
        "    # ---- filtering ----\n",
        "    \"similarity_threshold\": 0.9, # 0.95 -> keeps most slices, 0.05 -> keep only the most unique slices\n",
        "\n",
        "    \"umap\": {\n",
        "        \"n_neighbors\": 15,\n",
        "        \"min_dist\": 0.1\n",
        "    },\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "id": "jj6l092DIBpx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stats(x):\n",
        "    return {\n",
        "        \"mean\": float(np.mean(x)),\n",
        "        \"min\": float(np.min(x)),\n",
        "        \"max\": float(np.max(x)),\n",
        "        \"std\": float(np.std(x))\n",
        "    }\n",
        "\n",
        "def clear_existing_state(cfg):\n",
        "    if os.path.exists(cfg[\"data_file\"]):\n",
        "        print(\"üßπ Removing existing analysis data\")\n",
        "        os.remove(cfg[\"data_file\"])\n",
        "\n",
        "    if os.path.exists(cfg[\"output_folder\"]):\n",
        "        print(\"üßπ Removing existing cluster folders\")\n",
        "        for root, dirs, files in os.walk(cfg[\"output_folder\"], topdown=False):\n",
        "            for f in files:\n",
        "                os.remove(os.path.join(root, f))\n",
        "            for d in dirs:\n",
        "                os.rmdir(os.path.join(root, d))"
      ],
      "metadata": {
        "id": "2Evc6rJVc1k5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class SampleBrain:\n",
        "    def __init__(self, cfg):\n",
        "        self.cfg = cfg\n",
        "        self.sr = cfg[\"sample_rate\"]\n",
        "        self.df = pd.DataFrame()\n",
        "        self.features = None\n",
        "\n",
        "    def find_zero_crossing(self, y, idx):\n",
        "        if idx <= 0 or idx >= len(y) - 1:\n",
        "            return idx\n",
        "        win = int(0.02 * self.sr)\n",
        "        s = max(0, idx - win)\n",
        "        e = min(len(y), idx + win)\n",
        "        zc = np.where(np.diff(np.signbit(y[s:e])))[0]\n",
        "        if len(zc):\n",
        "            return s + zc[np.argmin(np.abs(zc - (idx - s)))]\n",
        "        return idx\n",
        "\n",
        "    def apply_envelope(self, y, fade_ms=5):\n",
        "        n = int((fade_ms / 1000) * self.sr)\n",
        "        if len(y) < 2 * n:\n",
        "            return y\n",
        "        env = np.ones(len(y))\n",
        "        env[:n] = np.linspace(0, 1, n)\n",
        "        env[-n:] = np.linspace(1, 0, n)\n",
        "        return y * env\n",
        "\n",
        "    def compute_umap(self, descriptor, n_neighbors=15, min_dist=0.1):\n",
        "        cols = self.feature_columns(descriptor)\n",
        "        if not cols:\n",
        "            raise RuntimeError(f\"No features found for {descriptor}\")\n",
        "\n",
        "        X = self.df[cols].fillna(0).values\n",
        "        X = StandardScaler().fit_transform(X)\n",
        "\n",
        "        reducer = umap.UMAP(\n",
        "            n_neighbors=n_neighbors,\n",
        "            min_dist=min_dist,\n",
        "            metric=\"cosine\",\n",
        "            random_state=42\n",
        "        )\n",
        "        emb = reducer.fit_transform(X)\n",
        "\n",
        "        self.df[f\"umap_{descriptor}_x\"] = emb[:, 0]\n",
        "        self.df[f\"umap_{descriptor}_y\"] = emb[:, 1]\n",
        "\n",
        "        print(f\"üó∫Ô∏è Built {descriptor} UMAP\")\n",
        "\n",
        "\n",
        "    def feature_columns(self, descriptor):\n",
        "        if descriptor == \"timbral\":\n",
        "            return [\n",
        "                c for c in self.df.columns\n",
        "                if c.startswith(\"mfcc_\") or c.startswith(\"mfcc_delta_\")\n",
        "            ]\n",
        "        elif descriptor == \"tonal\":\n",
        "            return [\n",
        "                c for c in self.df.columns\n",
        "                if c.startswith(\"chroma_\") or c.startswith(\"chroma_delta_\")\n",
        "            ]\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown descriptor: {descriptor}\")\n",
        "\n",
        "\n",
        "    def analyze(self):\n",
        "        if self._try_resume():\n",
        "            return\n",
        "\n",
        "        files = self._gather_audio_files()\n",
        "        rows = []\n",
        "\n",
        "        for i, path in enumerate(files):\n",
        "            print(f\"üîç [{i+1}/{len(files)}] {os.path.basename(path)}\")\n",
        "            rows.extend(self._process_file(path))\n",
        "\n",
        "        self.df = pd.DataFrame(rows)\n",
        "        self.save_dataframe()\n",
        "\n",
        "        print(f\"‚ú® Extracted {len(self.df)} slices\")\n",
        "\n",
        "        print(\"üó∫Ô∏è Computing UMAPs...\")\n",
        "        self.compute_umap(\"timbral\")\n",
        "        self.compute_umap(\"tonal\")\n",
        "\n",
        "    def _try_resume(self):\n",
        "        if self.cfg.get(\"resume\") and os.path.exists(self.cfg[\"data_file\"]):\n",
        "            self.load_dataframe()\n",
        "            print(f\"‚úÖ Loaded {len(self.df)} existing slices\")\n",
        "\n",
        "            if \"umap_timbral_x\" not in self.df.columns:\n",
        "                self.compute_umap(\"timbral\")\n",
        "            if \"umap_tonal_x\" not in self.df.columns:\n",
        "                self.compute_umap(\"tonal\")\n",
        "\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def _gather_audio_files(self):\n",
        "        cfg = self.cfg\n",
        "        files = []\n",
        "\n",
        "        for ext in (\"wav\", \"mp3\", \"aiff\"):\n",
        "            files += glob.glob(\n",
        "                os.path.join(cfg[\"input_folder\"], \"**\", f\"*.{ext}\"),\n",
        "                recursive=True\n",
        "            )\n",
        "\n",
        "        if cfg.get(\"file_limit\"):\n",
        "            files = files[: cfg[\"file_limit\"]]\n",
        "\n",
        "        print(f\"üìÇ Found {len(files)} audio files\")\n",
        "        return files\n",
        "\n",
        "    def _process_file(self, path):\n",
        "        rows = []\n",
        "\n",
        "        try:\n",
        "            y, _ = librosa.load(path, sr=self.sr, mono=False)\n",
        "            for ch, sig in self._iter_channels(y):\n",
        "                rows.extend(self._process_channel(path, ch, sig))\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error processing {os.path.basename(path)}: {e}\")\n",
        "\n",
        "        return rows\n",
        "\n",
        "    def _iter_channels(self, y):\n",
        "        cfg = self.cfg\n",
        "\n",
        "        if y.ndim == 1:\n",
        "            return [(\"mono\", y)]\n",
        "\n",
        "        if cfg[\"stereo_mode\"] == \"sum\":\n",
        "            return [(\"sum\", librosa.to_mono(y))]\n",
        "        if cfg[\"stereo_mode\"] == \"split\":\n",
        "            return [(\"L\", y[0]), (\"R\", y[1])]\n",
        "        if cfg[\"stereo_mode\"] == \"L\":\n",
        "            return [(\"L\", y[0])]\n",
        "        if cfg[\"stereo_mode\"] == \"R\":\n",
        "            return [(\"R\", y[1])]\n",
        "\n",
        "        return [(\"sum\", librosa.to_mono(y))]\n",
        "\n",
        "    def _process_channel(self, path, ch, sig):\n",
        "        rows = []\n",
        "        cfg = self.cfg\n",
        "\n",
        "        onsets = librosa.onset.onset_detect(\n",
        "            y=sig, sr=self.sr, units=\"samples\"\n",
        "        )\n",
        "        if len(onsets) == 0:\n",
        "            onsets = [0]\n",
        "\n",
        "        for j in range(len(onsets)):\n",
        "            s = onsets[j]\n",
        "            e = onsets[j + 1] if j + 1 < len(onsets) else len(sig)\n",
        "\n",
        "            s = self.find_zero_crossing(sig, s)\n",
        "            e = self.find_zero_crossing(sig, e)\n",
        "\n",
        "            dur = (e - s) / self.sr\n",
        "            if not (cfg[\"min_duration\"] <= dur <= cfg[\"max_duration\"]):\n",
        "                continue\n",
        "\n",
        "            row = self._extract_slice_features(\n",
        "                path, ch, sig, s, e, dur\n",
        "            )\n",
        "            if row:\n",
        "                rows.append(row)\n",
        "\n",
        "        return rows\n",
        "\n",
        "    def _extract_slice_features(self, path, ch, sig, s, e, dur):\n",
        "        slice_y = self.apply_envelope(sig[s:e])\n",
        "        y_fix = librosa.util.fix_length(slice_y, size=10240)\n",
        "\n",
        "        row = {\n",
        "            \"file_path\": path,\n",
        "            \"channel\": ch,\n",
        "            \"duration\": dur,\n",
        "            \"start_sample\": int(s),\n",
        "            \"end_sample\": int(e),\n",
        "            \"rolloff\": 0.0,\n",
        "            \"attack_slope\": 0.0,\n",
        "            \"loudness\": float(\n",
        "                np.mean(librosa.feature.rms(y=y_fix))\n",
        "            ),\n",
        "        }\n",
        "\n",
        "        self._add_mfcc_features(row, y_fix)\n",
        "        self._add_chroma_features(row, y_fix)\n",
        "        self._add_rolloff(row, y_fix)\n",
        "        self._add_attack_slope(row, slice_y)\n",
        "\n",
        "        return row\n",
        "\n",
        "    def _add_mfcc_features(self, row, y):\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=self.sr, n_mfcc=13)\n",
        "        mfcc_d = librosa.feature.delta(mfcc)\n",
        "\n",
        "        for k in range(13):\n",
        "            row[f\"mfcc_mean_{k}\"] = float(np.mean(mfcc[k]))\n",
        "            row[f\"mfcc_delta_mean_{k}\"] = float(np.mean(mfcc_d[k]))\n",
        "\n",
        "    def _add_chroma_features(self, row, y):\n",
        "        chroma = librosa.feature.chroma_stft(y=y, sr=self.sr)\n",
        "        chroma_d = librosa.feature.delta(chroma)\n",
        "\n",
        "        for k in range(12):\n",
        "            row[f\"chroma_mean_{k}\"] = float(np.mean(chroma[k]))\n",
        "            row[f\"chroma_delta_mean_{k}\"] = float(np.mean(chroma_d[k]))\n",
        "\n",
        "    def _add_rolloff(self, row, y):\n",
        "        try:\n",
        "            ro = librosa.feature.spectral_rolloff(y=y, sr=self.sr)\n",
        "            if ro.size > 0:\n",
        "                row[\"rolloff\"] = float(np.mean(ro))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    def _add_attack_slope(self, row, slice_y):\n",
        "        attack_len = int(0.05 * self.sr)\n",
        "        attack = slice_y[:attack_len]\n",
        "\n",
        "        if len(attack) > 8:\n",
        "            rms_env = librosa.feature.rms(y=attack)[0]\n",
        "            row[\"attack_slope\"] = float(\n",
        "                np.polyfit(\n",
        "                    np.arange(len(rms_env)),\n",
        "                    rms_env,\n",
        "                    1\n",
        "                )[0]\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "    def cluster(self, descriptor=\"timbral\", n_clusters=8):\n",
        "        cols = self.feature_columns(descriptor)\n",
        "        X = self.df[cols].fillna(0).values\n",
        "        X = StandardScaler().fit_transform(X)\n",
        "\n",
        "        print(f\"üß† Clustering ({descriptor}) {len(X)} slices...\")\n",
        "\n",
        "        km = KMeans(\n",
        "            n_clusters=n_clusters,\n",
        "            random_state=42,\n",
        "            n_init=\"auto\"\n",
        "        )\n",
        "        self.df[\"cluster\"] = km.fit_predict(X)\n",
        "\n",
        "        print(\"üìä Cluster distribution:\")\n",
        "        print(self.df[\"cluster\"].value_counts().sort_index())\n",
        "\n",
        "\n",
        "    # --- Robust scaling helper ---\n",
        "    def robust_scale_features(X):\n",
        "        \"\"\"Scale features using median/IQR, robust to outliers.\"\"\"\n",
        "        scaler = RobustScaler()\n",
        "        return scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "    def thin(self, descriptor=\"timbral\", percentile=90):\n",
        "        \"\"\"\n",
        "        Thins slices per cluster based on distance from cluster centroid.\n",
        "\n",
        "        Args:\n",
        "            descriptor: \"timbral\" or \"tonal\"\n",
        "            percentile: keep slices above this percentile distance within each cluster\n",
        "                        (0‚Äì100, higher = keep more distant slices)\n",
        "        \"\"\"\n",
        "        coords_cols = [f\"umap_{descriptor}_x\", f\"umap_{descriptor}_y\"]\n",
        "        X = self.df[coords_cols].values\n",
        "        X = MinMaxScaler().fit_transform(X)  # global scaling\n",
        "\n",
        "        keep_mask = np.zeros(len(self.df), dtype=bool)\n",
        "        print(f\"üîç Thinning similar slices using {descriptor} UMAP (percentile={percentile})...\")\n",
        "\n",
        "        for cid, idx in self.df.groupby(\"cluster\").groups.items():\n",
        "            cluster_X = X[list(idx)]\n",
        "            centroid = cluster_X.mean(axis=0, keepdims=True)\n",
        "            distances = np.linalg.norm(cluster_X - centroid, axis=1)\n",
        "\n",
        "            # Compute the threshold distance for this cluster\n",
        "            thresh = np.percentile(distances, percentile)\n",
        "            keep_mask[list(idx)] = distances >= thresh\n",
        "\n",
        "        before = len(self.df)\n",
        "        self.df = self.df[keep_mask].reset_index(drop=True)\n",
        "        print(f\"‚úÇÔ∏è Reduced {before} -> {len(self.df)} slices after thinning\")\n",
        "\n",
        "\n",
        "\n",
        "    def sort(self, descriptor=\"timbral\", mode=\"similarity\"):\n",
        "        if mode == \"duration\":\n",
        "            self.df = self.df.sort_values(\"duration\", ascending=False).reset_index(drop=True)\n",
        "            return\n",
        "\n",
        "        if mode == \"pitch\":\n",
        "            self.df = self.df.sort_values(\"f0_mean\", ascending=False).reset_index(drop=True)\n",
        "            return\n",
        "\n",
        "        if mode != \"similarity\":\n",
        "            raise ValueError(f\"Unknown sort mode: {mode}\")\n",
        "\n",
        "        coords_cols = [f\"umap_{descriptor}_x\", f\"umap_{descriptor}_y\"]\n",
        "        X = self.df[coords_cols].values\n",
        "        X = MinMaxScaler().fit_transform(X)  # global scaling\n",
        "\n",
        "        distances = np.zeros(len(self.df))\n",
        "        for cid, idx in self.df.groupby(\"cluster\").groups.items():\n",
        "            cluster_X = X[list(idx)]\n",
        "            centroid = cluster_X.mean(axis=0, keepdims=True)\n",
        "            distances[list(idx)] = np.linalg.norm(cluster_X - centroid, axis=1)\n",
        "\n",
        "        self.df[\"distance\"] = distances\n",
        "        self.df = self.df.sort_values([\"cluster\", \"distance\"], ascending=[True, True]).reset_index(drop=True)\n",
        "        print(f\"üìê Sorted by {descriptor} similarity (distance to cluster centroid)\")\n",
        "        print(f\"distance min/max: {self.df['distance'].min():.5f} / {self.df['distance'].max():.5f}\")\n",
        "\n",
        "\n",
        "\n",
        "    def save_dataframe(self):\n",
        "        path = self.cfg[\"data_file\"]\n",
        "        print(f\"üíæ Saving analysis data to {path}\")\n",
        "\n",
        "        df = self.df.copy()\n",
        "        # df[\"raw_audio\"] = df[\"raw_audio\"].apply(lambda x: x.tolist())\n",
        "        df.to_csv(path, index=False)\n",
        "\n",
        "    def load_dataframe(self):\n",
        "        path = self.cfg[\"data_file\"]\n",
        "        print(f\"üìÇ Loading analysis data from {path}\")\n",
        "\n",
        "        df = pd.read_csv(path)\n",
        "        # df[\"raw_audio\"] = df[\"raw_audio\"].apply(lambda x: np.array(eval(x)))\n",
        "        self.df = df\n",
        "\n",
        "\n",
        "    def export(self, sort_mode=\"timbral\"):\n",
        "        \"\"\"\n",
        "        Write slices to cluster directories, filenames include:\n",
        "            {global_index}-{sort_mode}-{distance:.3f}.wav\n",
        "        \"\"\"\n",
        "        out = self.cfg[\"output_folder\"]\n",
        "        os.makedirs(out, exist_ok=True)\n",
        "\n",
        "        if \"cluster\" not in self.df.columns:\n",
        "            raise RuntimeError(\"No clusters found. Run cluster() first.\")\n",
        "\n",
        "        if \"distance\" not in self.df.columns:\n",
        "            print(\"‚ö†Ô∏è Distance column not found. Running sort first...\")\n",
        "            self.sort(descriptor=sort_mode, mode=\"similarity\")\n",
        "\n",
        "        print(f\"üíæ Writing slices to {out}\")\n",
        "\n",
        "        audio_cache = {}\n",
        "\n",
        "        for i, row in enumerate(self.df.itertuples()):\n",
        "            path = row.file_path\n",
        "            start_sample = row.start_sample\n",
        "            end_sample = row.end_sample\n",
        "            cluster = row.cluster\n",
        "            channel = row.channel\n",
        "            distance = getattr(row, \"distance\", 0.0)\n",
        "\n",
        "            if path not in audio_cache:\n",
        "                y, _ = librosa.load(path, sr=self.sr, mono=True)\n",
        "                audio_cache[path] = y\n",
        "            else:\n",
        "                y = audio_cache[path]\n",
        "\n",
        "            slice_y = y[start_sample:end_sample]\n",
        "\n",
        "            # Create cluster folder\n",
        "            c_dir = os.path.join(out, f\"Cluster_{cluster}\")\n",
        "            os.makedirs(c_dir, exist_ok=True)\n",
        "\n",
        "            # Filename: global index - sort mode - distance\n",
        "            fn = f\"{i}-{sort_mode}-{distance:.3f}.wav\"\n",
        "            sf.write(os.path.join(c_dir, fn), slice_y, self.sr)\n",
        "\n",
        "        print(\"‚úÖ Export complete\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KYZ7jUCN3gsL"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    if CONFIG[\"clear_existing\"]:\n",
        "        clear_existing_state(CONFIG)\n",
        "\n",
        "    brain = SampleBrain(CONFIG)\n",
        "\n",
        "    brain.analyze()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dg9XIieb8r2a",
        "outputId": "c3f0c549-ea1f-41ac-a4b9-394a4f5cfb83"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßπ Removing existing analysis data\n",
            "üßπ Removing existing cluster folders\n",
            "üìÇ Found 3 audio files\n",
            "üîç [1/3] prepared piano study #9.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/librosa/core/pitch.py:103: UserWarning: Trying to estimate tuning from empty frequency set.\n",
            "  return pitch_tuning(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç [2/3] The Lily in a Crystal (after Herrick) for electromagnetically prepare piano.mp3\n",
            "üîç [3/3] Improvisation for Prepared Piano - Richard Melkonian.mp3\n",
            "üíæ Saving analysis data to /content/drive/My Drive/audio/sp-tools-corpora/preparedpiano/clusters/analysis_data.csv\n",
            "‚ú® Extracted 446 slices\n",
            "üó∫Ô∏è Computing UMAPs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üó∫Ô∏è Built timbral UMAP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üó∫Ô∏è Built tonal UMAP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "brain.cluster(descriptor=\"timbral\", n_clusters=5)\n",
        "brain.thin(descriptor=\"timbral\", percentile=50)\n",
        "brain.sort(descriptor=\"tonal\", mode=\"similarity\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ume9DlGzXxDj",
        "outputId": "f43684ad-3099-48d9-a545-a6eb4dd576e1"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Clustering (timbral) 421 slices...\n",
            "üìä Cluster distribution:\n",
            "cluster\n",
            "0    155\n",
            "1     62\n",
            "2    109\n",
            "3     31\n",
            "4     64\n",
            "Name: count, dtype: int64\n",
            "üîç Thinning similar slices using timbral UMAP (percentile=50)...\n",
            "‚úÇÔ∏è Reduced 421 -> 212 slices after thinning\n",
            "üìê Sorted by tonal similarity (distance to cluster centroid)\n",
            "distance min/max: 0.00999 / 0.82399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "brain.export()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ULJdv1vXzrd",
        "outputId": "6bbf1936-29da-4791-83ef-5043e8d91216"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Writing slices to /content/drive/My Drive/audio/sp-tools-corpora/preparedpiano/clusters\n",
            "‚úÖ Export complete\n"
          ]
        }
      ]
    }
  ]
}